{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9072, 29)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', rc={\"grid.linewidth\": 0.1})\n",
    "sns.set_context(\"paper\")    \n",
    "y_labels = [\"love\", \"haha\", \"wow\", \"angry\", \"sad\"]\n",
    "\n",
    "dataset = pd.read_json(\"data/preprocessed.json\")\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- The purpose of this is to quickly get a predictive model, it will serve as a benchmark for future works.\n",
    "\n",
    "- `GridSearchCV` may be the easiest way do Hyperparameter Optimization. Scripts for searching those optimal parameters are on folder `grid_search`.\n",
    "\n",
    "- And we are gonna use StratifiedKFold to deal with the **imbalanced** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "\n",
    "The classification score for this multilabel task must be an accuracy defined by\n",
    "$$\n",
    "accuracy(y, \\hat{y}) = \\frac{1}{N} \\sum_{i=1}^{N} 1(\\hat{y}_i = y_i)\n",
    "$$\n",
    "Where $N$ is the number of samples, $\\hat{y}_i$ is the predicted value of the i-th sample and $y_i$ is the corresponding true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predictive Model: TF-IDF + Linear SVC\n",
    "\n",
    "It is very common to follow the bag-of-words approach when extracting features from documents. One of the simplest feature model is TF-IDF.\n",
    "\n",
    "`CountVectorizer, TfidfTransformer`\n",
    "\n",
    "Now we can choose a learning algorithm/classifier, according to \"scikit learn\", http://scikit-learn.org/stable/_static/ml_map.png. The first one we should try is a linear-SVC.\n",
    "\n",
    "**Linear SVM (One vs Rest):** Is the first multiclass classifier we should try according to a guide from scikit-learn, and we evaluate its accuracy using K-Fold cross validation. \n",
    "\n",
    "The C parameter basically tells us how much you want to avoid misclassifying each sample.\n",
    "\n",
    "The thing now is to try with every possible value of $C > 1$. It is common to use exponentially growing sequences of 2, like $C = 2^{-5},2^{-3},\\ldots,2^{15}$.\n",
    "\n",
    "#### Hyperparameter Optimization\n",
    "\n",
    "I'd suggest running the file `tfidf_linearsvc.py`, but it takes like 1 hour. I'll write down those parameters and its score.\n",
    "\n",
    "#### Score\n",
    "\n",
    "``\n",
    "best_params_: {'vect__ngram_range': (1, 2), 'tfidf__use_idf': True, 'clf__C': 0.29999999999999999, 'vect__min_df': 2, 'vect__max_df': 1.0}\n",
    "best_score_: 0.724586549063\n",
    "``\n",
    "\n",
    "It is not the final model, I'll try with another feature models first.\n",
    "\n",
    "### 2. Predictive Model: TF-IDF + Naive Bayes\n",
    "\n",
    "Now, we should try with a Multinomial Naive Bayes. We can have those countings this algorithm needs using a `CountVectorizer`.\n",
    "\n",
    "#### Hyperparameter Optimization\n",
    "\n",
    "The same with file `tfidf_naivebayes.py`. I'll write down those parameters and its score.\n",
    "\n",
    "#### Score\n",
    "\n",
    "`\n",
    "best_params_: {'vect__ngram_range': (1, 1), 'tfidf__use_idf': False, 'vect__min_df': 4, 'vect__max_df': 0.040000000000000001}\n",
    "best_score_: 0.680044101433\n",
    "`\n",
    "\n",
    "### 3. Predictive Model: TF-IDF + Stochastic Gradient Descent\n",
    "\n",
    "The next one is SGD, I don't have more than 10K samples, and I didn't get a better score with it.\n",
    "\n",
    "#### Hyperparameter Optimization\n",
    "\n",
    "The same with file `tfidf_sgd.py`.\n",
    "\n",
    "#### Score\n",
    "\n",
    "`\n",
    "best_params_: {'vect__ngram_range': (1, 2), 'vect__max_df': 1.0, 'clf__n_iter': 10000, 'clf__loss': 'modified_huber', 'tfidf__use_idf': True, 'vect__min_df': 1, 'clf__penalty': 'l2', 'clf__alpha': 1e-05}\n",
    "best_score_: 0.692570546737\n",
    "`\n",
    "\n",
    "**And apparently a Linear SVC gives a better score, so I'll just keep using it but with another feature models, I won't try with any other Learning algorithm either since I just want a benchmark.**\n",
    "\n",
    "I will keep this SGD model to have the possibility to get the probability of belonging to each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature set in a 2D space\n",
    "\n",
    "\n",
    "![Image](notebook_figures/tfidf_2d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image was created running\n",
    "\n",
    "`\n",
    "visualization/tfidf_2d.py\n",
    "`\n",
    "\n",
    "It takes some minutes to save the scatter plot in `notebook_figures`, and it looks messy, I'll try with LDA."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
